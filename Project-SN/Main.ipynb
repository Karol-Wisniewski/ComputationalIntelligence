{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import text2emotion as te\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unavailable user in card on tweet 1660392261723496448\n",
      "User 14204245 not found in user refs in card on tweet 1660392261723496448\n",
      "Unavailable user in card on tweet 1660377399660355587\n",
      "User 14204245 not found in user refs in card on tweet 1660377399660355587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper('#BlackLivesMatter since:2022-05-22 until:2023-05-22').get_items()):\n",
    "    if i+1 > 1000:\n",
    "        break\n",
    "    tweets.append([tweet.id, tweet.date, tweet.user.username, tweet.rawContent, tweet.user.location, tweet.likeCount])\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['id', 'date', 'username', 'content', 'location', 'likes'])\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv('tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Deleting links\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Deleting hashtags and mentions\n",
    "    text = re.sub(r'#\\S+|@\\S+', '', text)\n",
    "    # # Deleting \n",
    "    # text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenizing and lemmatizing\n",
    "    text = word_tokenize(text)\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['processed_text'] = df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def emotion_analysis(text):\n",
    "    emotions = te.get_emotion(' '.join(text))\n",
    "    return emotions\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "    sentiment = sid.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "df['sentiment'] = df['processed_text'].apply(sentiment_analysis)\n",
    "df['emotions'] = df['processed_text'].apply(emotion_analysis)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x['compound'])\n",
    "df['emotions'] = df['emotions'].apply(lambda x: max(x, key=x.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_agg \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39msentiment\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      5\u001b[0m \u001b[39m# Pie chart for 'emotions'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\generic.py:1773\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1767\u001b[0m     \u001b[39m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m     \u001b[39m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1770\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1771\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1772\u001b[0m     )\n\u001b[1;32m-> 1773\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn not found: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key]\u001b[39m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: sentiment'"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by='date')\n",
    "df_agg = df.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Pie chart for 'emotions'\n",
    "plt.figure(figsize=(5,5))\n",
    "df['emotions'].value_counts().plot(kind='pie', autopct='%1.1f%%', explode=[0.1, 0, 0, 0, 0], shadow=True)\n",
    "plt.title('Emotions Pie Chart')\n",
    "plt.show() \n",
    "\n",
    "# Histogram for 'sentiment'\n",
    "plt.figure(figsize=(5,5))\n",
    "df['sentiment'].plot(kind='hist')\n",
    "plt.title('Sentiment Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Line chart for 'sentiment' over time\n",
    "plt.figure(figsize=(20,5))\n",
    "df_agg.plot(kind='line', x='date', y='sentiment')\n",
    "plt.title('Average sentiment over time')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  1000.000000\n",
      "mean      0.024150\n",
      "std       0.405744\n",
      "min      -0.953300\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.211025\n",
      "max       0.944200\n",
      "            0\n",
      "count    1000\n",
      "unique      5\n",
      "top     Happy\n",
      "freq      401\n"
     ]
    }
   ],
   "source": [
    "# Wyniki dla sentymentu\n",
    "sentiment_results = df['sentiment'].apply(pd.Series)\n",
    "print(sentiment_results.describe())\n",
    "\n",
    "# Wyniki dla emocji\n",
    "emotion_results = df['emotions'].apply(pd.Series)\n",
    "print(emotion_results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~df['content'].str.contains('@@@@@@@@')]\n",
    "# df = df[~df['content'].str.contains('http://')]\n",
    "# df = df[~df['content'].str.contains('https://')]\n",
    "# df = df.dropna()\n",
    "# df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
